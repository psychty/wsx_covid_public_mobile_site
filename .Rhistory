# Occurrences data is produced at ltla level and we would probably find it useful to aggregate to utla and region for our analysis
Occurrences_wsx <- Occurrences_ltla %>%
group_by(Cause, Week_number, Place_of_death) %>%
summarise(Deaths = sum(Deaths, na.rm = TRUE)) %>%
mutate(Name = 'West Sussex') %>%
select(Name, Week_number, Cause, Place_of_death, Deaths) %>%
left_join(week_ending, by = 'Week_number') %>%
ungroup()
Occurrences_england <- read_excel(paste0(github_repo_dir, '/Source_files/ons_mortality.xlsx'), sheet = 'Occurrences - All data', skip = 2) %>%
rename(Name = `Area name`,
Cause = `Cause of death`,
Week_number = `Week number`,
Place_of_death = `Place of death`,
Deaths = `Number of deaths`) %>%
filter(substr(`Area code`, 1,1) == 'E') %>%
group_by(Cause, Week_number, Place_of_death) %>%
summarise(Deaths = sum(Deaths, na.rm = TRUE)) %>%
mutate(Name = 'England') %>%
select(Name, Week_number, Cause, Place_of_death, Deaths) %>%
left_join(week_ending, by = 'Week_number') %>%
ungroup()
Occurrences_southeast <- read_excel(paste0(github_repo_dir, '/Source_files/ons_mortality.xlsx'), sheet = 'Occurrences - All data', skip = 2) %>%
rename(Name = `Area name`,
Cause = `Cause of death`,
Week_number = `Week number`,
Place_of_death = `Place of death`,
Deaths = `Number of deaths`) %>%
filter(`Area code` %in% lookup$LTLA19CD) %>%
group_by(Cause, Week_number, Place_of_death) %>%
summarise(Deaths = sum(Deaths, na.rm = TRUE)) %>%
mutate(Name = 'South East region') %>%
select(Name, Week_number, Cause, Place_of_death, Deaths) %>%
left_join(week_ending, by = 'Week_number') %>%
ungroup()
Occurrences_southeast_check <- read_excel(paste0(github_repo_dir, '/Source_files/ons_mortality.xlsx'), sheet = 'Occurrences - All data', skip = 2) %>%
rename(Name = `Area name`,
Cause = `Cause of death`,
Week_number = `Week number`,
Place_of_death = `Place of death`,
Deaths = `Number of deaths`) %>%
filter(`Area code` %in% lookup$LTLA19CD)
Occurrences_southeast_check %>%
select(Name) %>%
unique()
Occurrences<- Occurrences_ltla %>%
bind_rows(Occurrences_wsx) %>%
bind_rows(Occurrences_england) %>%
bind_rows(Occurrences_southeast)
rm(Occurrences_ltla, Occurrences_wsx, Occurrences_southeast, Occurrences_england)
deaths_labels <- Occurrences %>%
arrange(Week_number) %>%
select(Week_ending) %>%
unique() %>%
mutate(deaths_label = paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y')))
# calculating release date
Occurrences_meta_1 <- week_ending %>%
filter(Week_number == max(Occurrences$Week_number)) %>%
mutate(registered_by = Week_ending + 8,
published_on = Week_ending + 11) %>%
pivot_longer(cols = c(Week_ending, registered_by, published_on), names_to = 'Item') %>%
mutate(Label = format(value, '%A %d %B'))
Occurrences_meta_2 <- data.frame(Week_number = numeric(), Item = character()) %>%
add_row(Week_number = min(Occurrences$Week_number),
Item = 'First_week') %>%
add_row(Week_number = max(Occurrences$Week_number),
Item = 'Last_week') %>%
left_join(week_ending, by = 'Week_number') %>%
mutate(Label = paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y'))) %>%
rename(value = Week_ending)
Occurrences_meta_1 %>%
bind_rows(Occurrences_meta_2) %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/mortality_dates.json'))
weekly_all_place_all_deaths <- Occurrences %>%
filter(Cause == 'All causes') %>%
arrange(Week_number) %>%
group_by(Name, Week_ending) %>%
summarise(Deaths = sum(Deaths, na.rm = TRUE)) %>%
select(Name, Week_ending, Deaths) %>%
mutate(Week_ending = factor(paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y')), levels = deaths_labels$deaths_label)) %>%
rename(All_deaths = Deaths)
All_settings_occurrences <- Occurrences %>%
group_by(Name, Week_number, Week_ending, Cause) %>%
summarise(Deaths = sum(Deaths, na.rm = TRUE)) %>%
group_by(Name, Cause) %>%
arrange(Cause, Week_number) %>%
mutate(Cumulative_deaths = cumsum(Deaths))  %>%
ungroup()
weekly_all_place_deaths <- All_settings_occurrences %>%
filter(Name %in% Areas) %>%
arrange(Week_number) %>%
select(Name, Cause, Week_ending, Deaths) %>%
mutate(Week_ending = factor(paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y')), levels = deaths_labels$deaths_label)) %>%
pivot_wider(id_cols = c(Name, Week_ending),
names_from = Cause,
values_from = Deaths) %>%
mutate(`Non-Covid` = `All causes` - `COVID 19`) %>%
select(-`All causes`) %>%
gather(key = 'Cause', value = 'Deaths', `COVID 19`:`Non-Covid`) %>%
mutate(Cause = factor(Cause, levels = rev(c('Non-Covid', 'COVID 19')))) %>%
mutate(lab_posit = ifelse(Cause == 'Non-Covid', 1.5, -1)) %>%
left_join(weekly_all_place_all_deaths, by = c('Name', 'Week_ending'))
deaths_summary_1 <- All_settings_occurrences %>%
filter(Week_number == max(Week_number)) %>%
select(Name, Week_number, Week_ending, Cause, Deaths) %>%
mutate(Cause = paste0(Cause, ' deaths this week')) %>%
pivot_wider(names_from = Cause, values_from = Deaths)
deaths_summary_2 <- All_settings_occurrences %>%
filter(Week_number == max(Week_number)) %>%
select(Name, Week_number, Cause, Cumulative_deaths) %>%
mutate(Cause = paste0(Cause, ' deaths so far')) %>%
pivot_wider(names_from = Cause, values_from = Cumulative_deaths)
# Care home deaths
carehome_deaths_summary <- Occurrences %>%
filter(Place_of_death %in% 'Care home') %>%
arrange(Week_number) %>%
select(Name, Cause, Week_ending, Week_number, Deaths) %>%
# mutate(Week_ending = factor(paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b')), levels = deaths_labels$deaths_label)) %>%
mutate(Cause = paste0(Cause, ' deaths this week')) %>%
pivot_wider(id_cols = c(Name, Week_ending, Week_number),
names_from = Cause,
values_from = Deaths) %>%
group_by(Name) %>%
arrange(Name, Week_number) %>%
mutate(`All causes deaths so far` = cumsum(`All causes deaths this week`),
`COVID 19 deaths so far` = cumsum(`COVID 19 deaths this week`))  %>%
ungroup() %>%
filter(Week_number == max(Week_number)) %>%
mutate(Type = 'Care homes')
deaths_summary <- deaths_summary_1 %>%
left_join(deaths_summary_2, by = c('Name', 'Week_number')) %>%
mutate(Type = 'All places') %>%
bind_rows(carehome_deaths_summary) %>%
mutate(Label = paste0('week ', Week_number, ' (', format(Week_ending - 6, '%d-%B'), ' to ', format(Week_ending, '%d-%B'), ')')) %>%
rename(COVID_deaths_in_week = `COVID 19 deaths this week`,
COVID_deaths_cumulative = `COVID 19 deaths so far`,
All_cause_deaths_in_week = `All causes deaths this week`,
All_case_cumulative = `All causes deaths so far`) %>%
select(!c('Week_number', 'Week_ending'))
deaths_summary %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/mortality_summary.json'))
rm(deaths_summary_1, deaths_summary_2)
all_deaths_json_export <- All_settings_occurrences %>%
ungroup() %>%
select(Name, Week_number, Week_ending, Cause, Deaths) %>%
group_by(Name, Week_number, Week_ending) %>%
spread(Cause, Deaths) %>%
mutate(`Not attributed to Covid-19` = `All causes` - `COVID 19`) %>%
rename(`Covid-19` = `COVID 19`) %>%
mutate(Deaths_in_week_label = paste0('The total number of deaths occurring in the week ending ', format(Week_ending, '%d %B %Y'), ' in ', Name, ' was<b> ', format(`All causes`, big.mark = ',', trim = TRUE), '</b>. Of these, <b>', format(`Covid-19`, big.mark = ',', trim = TRUE), ifelse(`Covid-19` == 1, ' death</b> was', ' deaths</b> were'), ' attributed to Covid-19. This is ',  round((`Covid-19`/`All causes`) * 100, 1), '% of deaths occuring in this week.')) %>%
group_by(Name) %>%
mutate(Cumulative_deaths_all_cause = cumsum(`All causes`)) %>%
mutate(Cumulative_covid_deaths = cumsum(`Covid-19`)) %>%
mutate(Cumulative_deaths_label = paste0('As at ', format(Week_ending, '%d %B %Y'), ' in ', Name, ' the total cumulative number of deaths for 2020 was<b> ', format(Cumulative_deaths_all_cause, big.mark = ',', trim = TRUE), '</b>. The cumulative number of deaths where Covid-19 is recorded as a cause by this date was ', format(Cumulative_covid_deaths, big.mark = ',', trim = TRUE), '. This is ', round((Cumulative_covid_deaths/Cumulative_deaths_all_cause) * 100, 1), '% of deaths occuring by this week.')) %>%
mutate(Date_label = factor(paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y')), levels = deaths_labels$deaths_label))
all_deaths_json_export %>%
select(Name, Date_label, Week_number, `Covid-19`, `Not attributed to Covid-19`, Cumulative_covid_deaths, Cumulative_deaths_all_cause) %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/deaths_all_settings.json'))
all_deaths_json_export %>%
select(Name, `All causes`) %>%
group_by(Name) %>%
filter(`All causes` == max(`All causes`)) %>%
mutate(Limit = ifelse(`All causes`<= 50, round_any(`All causes`, 5, ceiling), ifelse(`All causes` <= 100, round_any(`All causes`, 10, ceiling), ifelse(`All causes` <= 250, round_any(`All causes`, 25, ceiling), ifelse(`All causes` <= 500, round_any(`All causes`, 50, ceiling), round_any(`All causes`, 100, ceiling)))))) %>%
ungroup() %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/deaths_limits_by_area.json'))
carehome_deaths_json_export <- Occurrences %>%
filter(Place_of_death %in% 'Care home') %>%
arrange(Week_number) %>%
select(Name, Cause, Week_ending, Week_number, Deaths) %>%
mutate(Date_label = factor(paste0('w/e ', ordinal(as.numeric(format(Week_ending, '%d'))), format(Week_ending, ' %b %y')), levels = deaths_labels$deaths_label)) %>%
pivot_wider(id_cols = c(Name, Week_ending, Week_number, Date_label),
names_from = Cause,
values_from = Deaths) %>%
mutate(`Not attributed to Covid-19` = `All causes` - `COVID 19`) %>%
gather(key = 'Cause', value = 'Deaths', `All causes`:`Not attributed to Covid-19`) %>%
select(Name, Week_number, Week_ending, Cause, Date_label, Deaths) %>%
group_by(Name, Week_number, Week_ending, Date_label) %>%
spread(Cause, Deaths) %>%
rename(`Covid-19` = `COVID 19`) %>%
mutate(Deaths_in_week_label = paste0('The total number of deaths occurring in care homes in the week ending ', format(Week_ending, '%d %B %Y'), ' in ', Name, ' was<b> ', format(`All causes`, big.mark = ',', trim = TRUE), '</b>. Of these, <b>', format(`Covid-19`, big.mark = ',', trim = TRUE), ifelse(`Covid-19` == 1, ' death</b> was', ' deaths</b> were'), ' attributed to Covid-19. This is ',  round((`Covid-19`/`All causes`) * 100, 1), '% of deaths occuring in care homes in this week.')) %>%
group_by(Name) %>%
mutate(Cumulative_deaths_all_cause = cumsum(`All causes`)) %>%
mutate(Cumulative_covid_deaths = cumsum(`Covid-19`)) %>%
mutate(Cumulative_deaths_label = paste0('As at ', format(Week_ending, '%d %B %Y'), ' in ', Name, ' the total cumulative number of deaths in care homes for 2020 was<b> ', format(Cumulative_deaths_all_cause, big.mark = ',', trim = TRUE), '</b>. The cumulative number of care home deaths where Covid-19 is recorded as a cause by this date was ', format(Cumulative_covid_deaths, big.mark = ',', trim = TRUE), '. This is ', round((Cumulative_covid_deaths/Cumulative_deaths_all_cause) * 100, 1), '% of deaths occuring by this week.'))
carehome_deaths_json_export %>%
select(Name, Week_number, Date_label, `Covid-19`, `Not attributed to Covid-19`, Cumulative_covid_deaths, Cumulative_deaths_all_cause) %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/deaths_carehomes.json'))
# PHE deaths any cause among COVID-19 + patients
# area_level <- 'ltla'
#
# phe_mortality_new_deaths <- read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=', area_level,'&metric=newDeathsByDeathDate&metric=newDeaths28DaysByDeathDate&metric=newDeaths28DaysByDeathDateRollingSum&metric=newDeaths28DaysByDeathDateRollingRate&metric=newDeaths60DaysByDeathDate&format=csv')) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=nation&areaCode=E92000001&metric=newDeathsByDeathDate&metric=newDeaths28DaysByDeathDate&metric=newDeaths28DaysByDeathDateRollingSum&metric=newDeaths28DaysByDeathDateRollingRate&metric=newDeaths60DaysByDeathDate&format=csv'))) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=region&areaCode=E12000008&metric=newDeathsByDeathDate&metric=newDeaths28DaysByDeathDate&metric=newDeaths28DaysByDeathDateRollingSum&metric=newDeaths28DaysByDeathDateRollingRate&metric=newDeaths60DaysByDeathDate&format=csv'))) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=utla&areaCode=E10000032&metric=newDeathsByDeathDate&metric=newDeaths28DaysByDeathDate&metric=newDeaths28DaysByDeathDateRollingSum&metric=newDeaths28DaysByDeathDateRollingRate&metric=newDeaths60DaysByDeathDate&format=csv'))) %>%
#   mutate(areaName = ifelse(areaName == 'South East', 'South East region', areaName)) %>%
#   filter(areaName %in% Areas) %>%
#   filter(date != last_date)
#
# phe_mortality_cumdeaths <- read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=', area_level,'&metric=cumDeathsByDeathDate&metric=cumDeaths28DaysByDeathDate&metric&metric=cumDeaths60DaysByDeathDate&format=csv')) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=nation&areaCode=E92000001&metric=cumDeathsByDeathDate&metric=cumDeaths28DaysByDeathDate&metric&metric=cumDeaths60DaysByDeathDate&format=csv'))) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=region&areaCode=E12000008&metric=cumDeathsByDeathDate&metric=cumDeaths28DaysByDeathDate&metric&metric=cumDeaths60DaysByDeathDate&format=csv'))) %>%
#   bind_rows(read_csv(paste0('https://api.coronavirus.data.gov.uk/v2/data?areaType=utla&areaCode=E10000032&metric=cumDeathsByDeathDate&metric=cumDeaths28DaysByDeathDate&metric&metric=cumDeaths60DaysByDeathDate&format=csv'))) %>%
#   mutate(areaName = ifelse(areaName == 'South East', 'South East region', areaName)) %>%
#   filter(areaName %in% Areas) %>%
#   filter(date == last_case_date)
#
# phe_mortality_new_deaths %>%
#   mutate(Period = format(date, '%d %B')) %>%
#   rename(Date = date,
#          Name = areaName,
#          Deaths = newDeathsByDeathDate,
#          Deaths_within28 = newDeaths28DaysByDeathDate,
#          Deaths_within28_rolling = newDeaths28DaysByDeathDateRollingSum,
#          Deaths_within28_rolling_rate = newDeaths28DaysByDeathDateRollingRate,
#          Deaths_within60 = newDeaths60DaysByDeathDate) %>%
#   select(Name, Date, Period, Deaths, Deaths_within28, Deaths_within28_rolling, Deaths_within28_rolling_rate, Deaths_within60) %>%
#   toJSON() %>%
#   write_lines(paste0(output_directory_x, '/covid_positive_deaths_all_cause.json'))
#
# phe_mortality_cumdeaths %>%
#   mutate(Period = format(date, '%d %B')) %>%
#   rename(Date = date,
#          Name = areaName,
#          Cumulative_deaths = cumDeathsByDeathDate,
#          Cumulative_deaths_28 = cumDeaths28DaysByDeathDate,
#          Cumulative_deaths_60 = cumDeaths60DaysByDeathDate) %>%
#   select(Name, Date, Period, Cumulative_deaths, Cumulative_deaths_28, Cumulative_deaths_60) %>%
#   toJSON() %>%
#   write_lines(paste0(output_directory_x, '/covid_positive_cumdeaths_all_cause.json'))
# MSOA map ####
if(!file.exists(paste0(github_repo_dir, '/Source_files/msoa_lookup_local.csv'))) {
oa_region <- read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv') %>%
select(OA11CD, RGN11NM)
msoa_names <- read_csv('https://visual.parliament.uk/msoanames/static/MSOA-Names-1.8.csv') %>%
select(msoa11cd, msoa11hclnm) %>%
rename(MSOA11CD = msoa11cd)
msoa_lookup <- read_csv('https://opendata.arcgis.com/datasets/6ecda95a83304543bc8feedbd1a58303_0.csv') %>%
left_join(read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv')[c('OA11CD', 'RGN11NM')], by = 'OA11CD') %>%
select(MSOA11CD, MSOA11NM, LAD11NM, RGN11NM) %>%
unique() %>%
left_join(msoa_names, by = 'MSOA11CD')
lsoa_to_msoa <- read_csv('https://opendata.arcgis.com/datasets/a46c859088a94898a7c462eeffa0f31a_0.csv') %>%
select(LSOA11CD, MSOA11CD, MSOA11NM) %>%
unique()
msoa_to_utla <- read_csv('https://opendata.arcgis.com/datasets/4c6f3314565e43c5ac7885fd71347548_0.csv') %>%
left_join(lsoa_to_msoa, by = 'LSOA11CD') %>%
select(MSOA11CD, UTLA19NM) %>%
mutate(UTLA19NM = ifelse(UTLA19NM %in% c('City of London', 'Hackney'), 'Hackney and City of London', ifelse(UTLA19NM %in% c('Cornwall', 'Isles of Scilly'), 'Cornwall and Isles of Scilly', UTLA19NM))) %>%
filter(!is.na(MSOA11CD)) %>%
unique()
msoa_lookup %>%
left_join(msoa_to_utla, by = 'MSOA11CD') %>%
write.csv(., paste0(github_repo_dir, '/Source_files/msoa_lookup_local.csv'), row.names = FALSE)
}
msoa_lookup <- read_csv(paste0(github_repo_dir, '/Source_files/msoa_lookup_local.csv'))
se_msoas <- msoa_lookup %>%
filter(RGN11NM == 'South East')
wsx_msoas <- msoa_lookup %>%
filter(LAD11NM %in% c('Adur', 'Arun', 'Chichester','Crawley', 'Horsham', 'Mid Sussex', 'Worthing'))
# Weekly rolling sums and population-based rates of new cases by specimen date time series data are available to download for English MSOAs via the following links. The data are updated each day, and show the latest 7 days for which near-complete data release date minus 5 days are available, and historic non-overlapping 7-day blocks. Dates are the final day in the relevant 7-day block, and counts between 0 and 2 are blank in the CSV or NULL in the other formats.
# This stopped on the 28th November!!!
# legacy_msoa_case_df <- read_csv('https://coronavirus.data.gov.uk/downloads/msoa_data/MSOAs_latest.csv')
msoa_data <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=msoa&metric=newCasesBySpecimenDateRollingSum&metric=newCasesBySpecimenDateRollingRate&format=csv')
msoa_cases_1 <-  msoa_data %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum, newCasesBySpecimenDateRollingRate) %>%
# filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
filter(date %in% c(max(date))) %>%
select(areaCode, date, newCasesBySpecimenDateRollingRate) %>%
rename(Latest_rate = newCasesBySpecimenDateRollingRate) %>%
mutate(Latest_rate_key = factor(ifelse(is.na(Latest_rate), 'Less than 3 cases', ifelse(Latest_rate <= 50, 'Up to 50 per 100,000', ifelse(Latest_rate <= 100, '51-100 cases per 100,000', ifelse(Latest_rate <= 150, '101-150 cases per 100,000', ifelse(Latest_rate <= 200, '151-200 cases per 100,000', 'More than 200 cases per 100,000'))))), levels = c('Less than 3 cases', 'Up to 50 cases per 100,000', '51-100 cases per 100,000', '101-150 cases per 100,000', '151-200 cases per 100,000', 'More than 200 cases per 100,000')))
msoa_cases_raw <- as.data.frame(msoa_data %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum, newCasesBySpecimenDateRollingRate) %>%
# filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
group_by(areaCode, areaName) %>%
arrange(areaCode, areaName, date) %>%
filter(date %in% c(max(date), max(date) - 7)) %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum) %>%
mutate(date = ifelse(date == max(date), 'This_week', ifelse(date == max(date)-7, 'Last_week', NA))) %>%
pivot_wider(names_from = 'date', values_from = 'newCasesBySpecimenDateRollingSum') %>%
mutate(Change_actual = This_week - Last_week) %>%
mutate(Change_label = ifelse(is.na(Last_week) & is.na(This_week), 'Cases below 3 in both weeks', ifelse(is.na(Last_week), 'Cases below 3 in previous week but have risen', ifelse(is.na(This_week), 'Cases below 3 in the latest 7 days but have fallen', ifelse(Change_actual == 0, 'No change in case numbers', ifelse(Change_actual < 0, 'Cases have fallen', ifelse(Change_actual>0, 'Cases have risen', NA))))))) %>%
mutate(Case_key = ifelse(is.na(This_week), '0-2 cases', ifelse(This_week <= 5, '3-5 cases', ifelse(This_week <= 10, '6-10 cases', ifelse(This_week <= 15, '11-15 cases', 'More than 15 cases'))))) %>%
left_join(msoa_cases_1, by = 'areaCode') %>%
left_join(msoa_lookup, by = c('areaCode' = 'MSOA11CD')) %>%
mutate(Label = paste0('<b>', MSOA11NM,' (', msoa11hclnm,')</b><br><br>In the seven days to ', format(date, '%A %d %B'), ' there were ', ifelse(is.na(This_week), ' less than three new cases.', paste0(format(This_week, big.mark = ',', trim = TRUE), ' new cases, this is a rate of ', round(Latest_rate, 1), ' cases per 100,000 population.')), '<br><br>', ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('Cases have fallen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('Cases have risen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
ungroup())
msoa_cases <- msoa_cases_raw %>%
select(MSOA11NM, Case_key, Latest_rate_key, Change_label, Label) %>%
#  filter(MSOA11NM %in% se_msoas$MSOA11NM) %>%
arrange(MSOA11NM)
msoa_boundaries_json <- geojson_read("https://opendata.arcgis.com/datasets/23cdb60ee47e4fef8d72e4ee202accb0_0.geojson",  what = "sp") %>%
filter(MSOA11NM %in% msoa_cases$MSOA11NM) %>%
arrange(MSOA11NM)
# download.file("https://opendata.arcgis.com/datasets/23cdb60ee47e4fef8d72e4ee202accb0_0.geojson", paste0(github_repo_dir, '/Source_files/failsafe_msoa_boundary.geojson'), mode = 'wb')
df <- data.frame(ID = character())
# Get the IDs of spatial polygon
for (i in msoa_boundaries_json@polygons ) { df <- rbind(df, data.frame(ID = i@ID, stringsAsFactors = FALSE))  }
# and set rowname = ID
row.names(msoa_cases) <- df$ID
# Then use df as the second argument to the spatial dataframe conversion function:
msoa_boundaries_json <- SpatialPolygonsDataFrame(msoa_boundaries_json, msoa_cases)
# geojson_write(ms_simplify(geojson_json(utla_ua_boundaries_rate_geo), keep = 0.2), file = paste0(output_directory_x, '/utla_covid_rate_latest.geojson'))
geojson_write(ms_simplify(geojson_json(msoa_boundaries_json), keep = 0.2), file = paste0(output_directory_x, '/msoa_covid_rate_latest.geojson'))
msoa_cases_raw %>%
select(MSOA11NM, msoa11hclnm, Latest_rate, LAD11NM, This_week, Last_week, Change_label, date, Change_actual) %>%
mutate(Change_label = paste0(ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('<b class = "cases_go_down">', Change_actual, '</b> cases compared to the previous 7 days (', Last_week,  ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('<b class = "cases_go_up">+', Change_actual, '</b> cases compared to the previous 7 days (', Last_week, ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
mutate(This_week = ifelse(is.na(This_week), '0-2', format(This_week, big.mark = ',', trim = TRUE)),
Last_week = ifelse(is.na(Last_week), '0-2', format(Last_week, big.mark = ',', trim = TRUE)),
Latest_rate = ifelse(is.na(Latest_rate), 'No rate available', Latest_rate)) %>%
select(!c('date', 'Change_actual')) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/msoa_summary.json'))
ltla_summary_1 <- p12_test_df %>%
filter(Type %in% c('Unitary Authority', 'Lower Tier Local Authority')) %>%
filter(Date == last_case_date) %>%
select(Name, Date, Cumulative_cases, Cumulative_per_100000) %>%
rename(Cumulative_date = Date)
ltla_summary_2 <- p12_test_df %>%
filter(Type %in% c('Unitary Authority', 'Lower Tier Local Authority')) %>%
filter(Date %in% c(complete_date)) %>%
select(Name, Date, New_cases, New_cases_per_100000, Rolling_7_day_new_cases, Rolling_7_day_new_cases_per_100000, Rolling_7_day_average_new_cases, Perc_change_on_rolling_7_days_actual, Previous_7_days_sum) %>%
mutate(Change_direction = ifelse(Perc_change_on_rolling_7_days_actual <0, 'Down', ifelse(Perc_change_on_rolling_7_days_actual == 0, 'Same', ifelse(Perc_change_on_rolling_7_days_actual > 0, 'Up', NA)))) %>%   rename(Rate_date = Date)
ltla_summary <- ltla_summary_1 %>%
left_join(ltla_summary_2, by = 'Name') %>%
left_join(read_csv(paste0(github_repo_dir, '/Source_files/ltla_tiers.csv'))[c('Area code', 'Name', 'Tier', 'Primary_schools')], by = 'Name') %>%
mutate(Change_label = ifelse(Change_direction == 'Down', paste0('decreased by ', format(abs(Previous_7_days_sum - Rolling_7_day_new_cases), big.mark = ',', trim = TRUE), ' cases (', round(abs(Perc_change_on_rolling_7_days_actual) * 100,1), '%)'),ifelse(Change_direction == 'Up', paste0('increased by ',   format(abs(Previous_7_days_sum - Rolling_7_day_new_cases), big.mark = ',', trim = TRUE), ' cases (', round(abs(Perc_change_on_rolling_7_days_actual) * 100,1), '%)'), 'stayed the same.'))) %>%
unique()
ltla_summary %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/ltla_summary.json'))
ltla_boundaries <- geojson_read('https://opendata.arcgis.com/datasets/3a4fa2ce68f642e399b4de07643eeed3_0.geojson',  what = "sp")
#download.file('https://opendata.arcgis.com/datasets/3a4fa2ce68f642e399b4de07643eeed3_0.geojson', paste0(github_repo_dir, '/Source_files/failsafe_ltla_boundary.geojson'), mode = 'wb')
if(exists('ltla_boundaries') == FALSE) {
ltla_boundaries <- geojson_read(paste0(github_repo_dir, '/Source_files/failsafe_ltla_boundary.geojson'),  what = "sp")
}
# utla_restrictions_geojson <-geojson_read("https://opendata.arcgis.com/datasets/b216b4c8a4e74f6fb692a1785255d777_0.geojson",  what = "sp") %>%
#   filter(substr(ctyua19cd, 1,1 ) == 'E') %>%
#   mutate(ctyua19nm = ifelse(ctyua19nm %in% c('Cornwall', 'Isles of Scilly'), 'Cornwall and Isles of Scilly', ifelse(ctyua19nm %in% c('City of London', 'Hackney'), 'Hackney and City of London', ctyua19nm))) %>%
#   mutate(ctyua19cd = ifelse(ctyua19cd %in% c('E06000053', 'E06000052'), 'E06000052', ifelse(ctyua19cd %in% c('E09000001', 'E09000012'), 'E09000012', ctyua19cd))) %>%
#   group_by(ctyua19cd, ctyua19nm) %>%
#   summarise() %>%
#   arrange(ctyua19cd) %>%
#   left_join(utla_summary, by = c('ctyua19nm' = 'Name'))
# geojson_write(geojson_json(utla_restrictions_geojson), file = paste0(output_directory_x, '/utla_covid_latest.geojson'))
ltla_restrictions_geojson <- ltla_boundaries %>%
filter(lad19cd %in% ltla_summary$`Area code`) %>%
arrange(lad19nm)
ltla_summary <- ltla_summary %>%
arrange(Name)
#left_join(ltla_summary, by = c('lad19nm' = 'Name'))
df <- data.frame(ID = character())
# Get the IDs of spatial polygon
for (i in ltla_restrictions_geojson@polygons ) { df <- rbind(df, data.frame(ID = i@ID, stringsAsFactors = FALSE))  }
# and set rowname = ID
row.names(ltla_summary) <- df$ID
# Then use df as the second argument to the spatial dataframe conversion function:
ltla_restrictions_geojson <- SpatialPolygonsDataFrame(ltla_restrictions_geojson, ltla_summary)
geojson_write(geojson_json(ltla_restrictions_geojson), file = paste0(output_directory_x, '/ltla_covid_latest.geojson'))
# daily_cases_df %>%
#   filter(Name == 'West Sussex') %>%
#   # filter(Date <= '2020-11-05') %>%
#   arrange(-Rolling_7_day_new_cases_per_100000) %>%
#   View()
# Growth Rates ####
growth_rate <- p12_test_df %>%
filter(Data_completeness == 'Complete') %>%
filter(Date >= complete_date -10) %>%
select(Name, Code, Type, Date, Rolling_7_day_new_cases, Perc_change_on_rolling_7_days_actual, Population) %>%
mutate(Rolling_7_day_new_cases = replace_na(Rolling_7_day_new_cases, 0)) %>%
mutate(Rolling_7_day_rate = pois.exact(Rolling_7_day_new_cases, Population)[[3]]*100000) %>%
mutate(Rolling_rate_lcl = pois.exact(Rolling_7_day_new_cases, Population)[[4]]*100000) %>%
mutate(Rolling_rate_ucl = pois.exact(Rolling_7_day_new_cases, Population)[[5]]*100000) %>%
arrange(Name, Date) %>%
group_by(Name) %>%
mutate(Last_week_incidence_rate = lag(Rolling_7_day_rate, 7),
Last_week_date = lag(Date, 7)) %>%
ungroup() %>%
filter(Date == complete_date) %>%
rename(Change_actual_by_week = Perc_change_on_rolling_7_days_actual)
growth_rate_england <- growth_rate %>%
filter(Name == 'England') %>%
rename(Eng_rate = Rolling_7_day_rate,
Eng_lcl = Rolling_rate_lcl,
Eng_ucl = Rolling_rate_ucl)
growth_rate_ltla <- growth_rate %>%
left_join(growth_rate_england[c('Date', 'Eng_rate', 'Eng_lcl', 'Eng_ucl')], by = 'Date') %>%
filter(Type %in% c('Lower Tier Local Authority', 'Unitary Authority') | Name == 'England')
growth_rate_ltla %>%
mutate(Name = factor(Name, levels = c(setdiff(unique(growth_rate_ltla$Name), c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex','Worthing', 'England')), c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex','Worthing', 'England')))) %>%
arrange(Name) %>%
select(Name, Date, Rolling_7_day_rate, Change_actual_by_week) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/ltla_growth_complete_date.json'))
# Positivity
positivity_ltla <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=ltla&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&metric=newVirus&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_utla <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=utla&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_region <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=region&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_nation <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=nation&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_df <- positivity_ltla %>%
bind_rows(positivity_utla) %>%
bind_rows(positivity_region) %>%
bind_rows(positivity_nation) %>%
unique() %>%
filter(Name %in% c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East', 'England')) %>%
mutate(Name = ifelse(Name == 'South East', 'South East region', Name))
positivity_at_a_glance <- positivity_df %>%
filter(Date == complete_date) %>%
select(Name, uniquePeopleTestedBySpecimenDateRollingSum, uniqueCasePositivityBySpecimenDateRollingSum) %>%
rename(`Number of people receiving a PCR (Polymerase chain reaction) test` = uniquePeopleTestedBySpecimenDateRollingSum,
`Positivity rate (weekly percentage of individuals tested who test positive for COVID-19)` = uniqueCasePositivityBySpecimenDateRollingSum)
at_a_glance_all <- at_a_glance_1 %>%
filter(Age == 'All ages') %>%
select(Name, Rolling_7_day_new_cases ,Rolling_7_day_new_cases_per_100000) %>%
mutate(Rolling_7_day_new_cases_per_100000 = round(Rolling_7_day_new_cases_per_100000, 1)) %>%
rename(Cases = Rolling_7_day_new_cases,
`Rate per 100,000` = Rolling_7_day_new_cases_per_100000)
at_a_glance_60s <- at_a_glance_1 %>%
filter(Age == '60+ years') %>%
select(Name, Rolling_7_day_new_cases_per_100000) %>%
mutate(Rolling_7_day_new_cases_per_100000 = round(Rolling_7_day_new_cases_per_100000, 1)) %>%
rename(`Rate of cases per 100,000 for people aged 60 and over` = Rolling_7_day_new_cases_per_100000)
public_latest_rates_table <- at_a_glance_all %>%
left_join(positivity_at_a_glance, by = 'Name') %>%
left_join(at_a_glance_60s, by = 'Name') %>%
select(Name, Cases, `Rate per 100,000`,  `Positivity rate (weekly percentage of individuals tested who test positive for COVID-19)`, `Number of people receiving a PCR (Polymerase chain reaction) test`, `Rate of cases per 100,000 for people aged 60 and over`)
public_latest_rates_table %>%
mutate(Name = factor(Name, levels = c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East region', 'England'))) %>%
arrange(Name) %>%
mutate(Date = complete_date) %>%
write.csv(., paste0(output_directory_x, '/public_latest_rates_table.csv'), row.names = FALSE)
# The number of people who received a PCR test in the previous 7 days, and the percentage of people who received a PCR test in the previous 7 days, who had at least one positive COVID-19 PCR test result.
# Polymerase chain reaction (PCR) tests are lab-based and test for the presence of SARS-CoV-2 virus. This data shows the number of people who received a PCR test in the previous 7 days, and the percentage of people who received a PCR test in the previous 7 days who had at least one positive PCR test result.
# If a person has had more than one test result in the 7-day period, they are only counted once. If any of their tests in that period were positive, they count as one person with a positive test result. The positivity percentage is the number of people with a positive test result, divided by the number of people tested and multiplied by 100.
# Individuals tested more than once in the period are only counted once in the denominator, and those with more than one positive test result in the period are only included once in the numerator.
positivity_worked <- positivity_df %>%
rename(Seven_day_PCR_positivity = uniqueCasePositivityBySpecimenDateRollingSum,
Seven_day_PCR_tested_individuals = uniquePeopleTestedBySpecimenDateRollingSum) %>%
group_by(Name) %>%
arrange(Name, Date) %>%
mutate(Perc_change_on_individuals_tested = round((Seven_day_PCR_tested_individuals - lag(Seven_day_PCR_tested_individuals, 7))/ lag(Seven_day_PCR_tested_individuals, 7), 2))  %>%
mutate(Perc_change_on_individuals_tested = ifelse(Perc_change_on_individuals_tested == Inf, 1, Perc_change_on_individuals_tested)) %>%
mutate(Perc_change_on_individuals_tested = replace_na(Perc_change_on_individuals_tested, 0)) %>%
mutate(Name = factor(Name, levels = c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East region', 'England'))) %>%
arrange(Name, Date) %>%
filter(Date >= max(Date) - 90)
positivity_worked %>%
filter(Date == complete_date)
positivity_worked %>%
select(!Code) %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/positivity_df.json'))
library(lemon)
data_dummy_positivity_worked <- positivity_worked %>%
rename(dummy_name = Name)
positivity_worked_plotted <- ggplot(positivity_worked,
aes(x = Date,
y = Seven_day_PCR_positivity,
colour = Name)) +
geom_line(data = data_dummy_positivity_worked,
aes(x = Date,
y = Seven_day_PCR_positivity,
group = dummy_name),
colour = '#dbdbdb',
size = .6) +
geom_line(size = .9) +
geom_point(size = .5) +
ph_theme() +
theme(axis.text.x = element_text(angle = 90, size = 6),
legend.position = 'none') +
scale_y_continuous(labels = label_comma(accuracy = 1, suffix = '%'),
limits = c(0,30),
breaks = seq(0, 30, 5)) +
scale_x_date(date_labels = "%b %d",
breaks = seq.Date(max(positivity_worked$Date) -(52*7), max(positivity_worked$Date), by = 7),
limits = c(min(positivity_worked$Date), max(positivity_worked$Date) + 7),
expand = c(0.01,1)) +
labs(x = '',
y = '7-day rolling PCR case positivity rate',
title = paste0('7-day PCR Case positivity rate for Covid-19 in the last 90 days; West Sussex, South East region, and England'),
subtitle = paste0('Pillar 1 and 2 combined; data as at ', format(last_date, '%d %B %Y')))  +
theme(axis.text.x = element_text(size = 8)) +
facet_rep_wrap(. ~ Name, ncol = 4, repeat.tick.labels = TRUE)
png(paste0(output_directory_x, '/Figure_7_day_rolling_positivity_rates_latest_faceted.png'),
width = 1480,
height = 880,
res = 130)
print(positivity_worked_plotted)
dev.off()
